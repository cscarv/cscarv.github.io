---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
published: true
redirect_from:
  - /research
---


Generative models have driven some the most exciting developments in machine learning, from [image synthesis](https://arxiv.org/abs/2112.10752) to [text generation](https://arxiv.org/abs/2204.02311) to [drug discovery](https://arxiv.org/abs/2210.01776). But despite steady progress in reducing their size and speeding up their training, generative models – implemented in practice using neural networks – remain very *costly* to train and to sample from. For example, [a single training run for Stable Diffusion costs $600,000](https://the-decoder.com/training-cost-for-stable-diffusion-was-just-600000-and-that-is-a-good-sign-for-ai-progress/).

Furthermore, generative models are black boxes: We can generate samples from a generative model but know little about their distribution. This limits the use of such models in sensitive applications such as healthcare, where adoption of AI-driven methods hinges on their *interpretability*.

Motivated by these pressing challenges, my research questions the role of neural networks in generative modeling and seeks to build **generative models without neural networks**. These models require no training, are efficient to sample from, and are based on well-understood classical methods.

I aim to make generative AI *accessible* by reducing our domain's reliance on costly and poorly-understood models in favor of efficient and well-understood methods that are transparent to both theoreticians and end users and can run on commodity hardware. Through my emphasis on *interpretability*, I also seek to further broaden the impact of generative AI by developing models that are suitable for sensitive domains.
